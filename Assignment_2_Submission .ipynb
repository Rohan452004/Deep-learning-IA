{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab Lab Assignment -Pretrained Modle\n",
        "\n",
        "**Course Name:** [Deep Learning]\n",
        "\n",
        "**Lab Title:** Research Paper Implementation with Pre-trained Model(Tilte of Research Paper)\n",
        "\n",
        "**Student Name:**[Rohan Agrawal]\n",
        "\n",
        "**Student ID:**[202201040208]\n",
        "\n",
        "**Date of Submission:** [24/03/25]\n",
        "\n",
        "**Group Members**: [Enter Names]\n",
        "\n",
        "**Research Paper Study and Implementation**\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Identify a research paper that utilizes a pre-trained model for a specific\n",
        "task.\n",
        "\n",
        "2. Study the methodology, dataset, and model used in the research paper.\n",
        "\n",
        "3. Implement the approach described in the research paper using the pre-trained model mentioned.\n",
        "\n",
        "4. Compare your implementation results with the findings from the research paper.\n"
      ],
      "metadata": {
        "id": "KRS_r90YMbta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective**\n",
        "1.   Study a research paper utilizing a pre-trained model.\n",
        "2.   Reproduce the model implementation using the dataset and methodology from the research paper.\n",
        "3.   Fine-tune the pre-trained model and optimize hyperparameters.\n",
        "3.   Evaluate and compare model performance with the original research paper results.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x1bukTjpNEze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1: Research Paper Selection and Dataset Preparation (2 hours)**\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Select a research paper that applies a pre-trained model (e.g., VGG, ResNet, EfficientNet, etc.).\n",
        "\n",
        "2. Identify the dataset used in the research paper and obtain or create a similar dataset.(**Mention Dataset Link and Description**)\n",
        "\n",
        "3. Perform necessary preprocessing steps:\n",
        "\n",
        " Resize images to match the model input dimensions.\n",
        "\n",
        " Apply data augmentation techniques if applicable.\n",
        "\n",
        "4. Split the dataset into training, validation, and testing sets."
      ],
      "metadata": {
        "id": "MD4ComqSNYGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code of task1"
      ],
      "metadata": {
        "id": "b85tIhfNNDlo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Model Implementation and Fine-tuning**\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Implement the pre-trained model as described in the research paper.\n",
        "\n",
        "2. Visualize feature maps of few layers\n",
        "\n",
        "3. Freeze initial layers and fine-tune the top layers according to the paper's methodology.\n",
        "\n",
        "4. Optimize hyperparameters such as:\n",
        "\n",
        "  Learning rate\n",
        "\n",
        "  Batch size\n",
        "\n",
        "  Number of epochs\n",
        "\n",
        "  Optimizer choice (Adam, SGD, RMSprop, etc.)\n",
        "\n",
        "4. Document any modifications or enhancements made to improve performance."
      ],
      "metadata": {
        "id": "8ezJvo9rNwsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code of Task 2"
      ],
      "metadata": {
        "id": "0U8RIdCPNo3J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3: Model Evaluation and Performance Comparison**\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Evaluate the trained model using performance metrics:\n",
        "\n",
        " Accuracy, Precision,Recall, F1-score, Confusion Matrix (for classification tasks)\n",
        "\n",
        "2. Compare the results with those reported in the research paper.\n",
        "\n",
        "3. Identify potential weaknesses and suggest improvements.\n",
        "**Deliverables:**\n",
        "\n",
        "Performance metrics summary (table or chart).\n",
        "\n",
        "Graphs/plots showcasing model accuracy and loss trends.\n",
        "\n",
        "Comparison with research paper results.\n",
        "\n",
        "Discussion on model performance and areas for improvement."
      ],
      "metadata": {
        "id": "MNDL5cN0M-xP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GJDKxaIdL__E"
      },
      "outputs": [],
      "source": [
        "##Code for Task 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion and Result Visulaization**"
      ],
      "metadata": {
        "id": "ffTHUJy_OeTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Declaration**\n",
        "\n",
        "I, Rohan Agrawal, confirm that the work submitted in this assignment is my own and has been completed following academic integrity guidelines. The code is uploaded on my GitHub repository account, and the repository link is provided below:\n",
        "\n",
        "GitHub Repository Link: [Insert GitHub Link]\n",
        "\n",
        "Signature: Rohan Agrawal"
      ],
      "metadata": {
        "id": "24O7V4AmOsF8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqMT0hT0vsio"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "\n",
        "✔ Research paper details and summary\n",
        "\n",
        "✔ Code file (Python Notebook or Script)\n",
        "\n",
        "✔ Dataset or link to the dataset\n",
        "\n",
        "✔ Visualizations (if applicable)\n",
        "\n",
        "✔ Screenshots of model performance metrics\n",
        "\n",
        "✔ Readme File\n",
        "\n",
        "✔ Comparison with research paper results"
      ],
      "metadata": {
        "id": "zioOSgLJOwHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Secure the file\n"
      ],
      "metadata": {
        "id": "vl9qa6A4uTw5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d alxmamaev/flowers-recognition\n",
        "!unzip flowers-recognition.zip -d /content/dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n73qYB5BtvqO",
        "outputId": "7e8fda1b-9a4d-48fe-b4cf-8269d5e02de7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alxmamaev/flowers-recognition\n",
            "License(s): unknown\n",
            "Archive:  flowers-recognition.zip\n",
            "  inflating: /content/dataset/flowers/daisy/100080576_f52e8ee070_n.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10140303196_b88d3d6cec.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10172379554_b296050f82_n.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10172567486_2748826a8b.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10172636503_21bededa75_n.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/102841525_bd6628ae3c.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10300722094_28fa978807_n.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/1031799732_e7f4008c03.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10391248763_1d16681106_n.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10437754174_22ec990b77_m.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10437770546_8bb6f7bdd3_m.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10437929963_bc13eebe0c.jpg  \n",
            "  inflating: /content/dataset/flowers/daisy/10466290366_cc72e33532.jpg  \n",
            "  inflating: /content/dataset/flowers/tulip/9976515506_d496c5e72c.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# Define source and destination paths\n",
        "src_folder = \"/content/dataset/flowers\"  # Current folder containing all categories\n",
        "train_folder = \"/content/dataset/train\"\n",
        "val_folder = \"/content/dataset/val\"\n",
        "test_folder = \"/content/dataset/test\"\n",
        "\n",
        "# Create directories if they don’t exist\n",
        "for folder in [train_folder, val_folder, test_folder]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "# Split dataset into train (80%), val (10%), and test (10%)\n",
        "for category in os.listdir(src_folder):\n",
        "    category_path = os.path.join(src_folder, category)\n",
        "    if os.path.isdir(category_path):  # Ensure it's a directory\n",
        "        images = os.listdir(category_path)\n",
        "        np.random.shuffle(images)\n",
        "\n",
        "        train_split = int(0.8 * len(images))\n",
        "        val_split = int(0.9 * len(images))\n",
        "\n",
        "        for i, img in enumerate(images):\n",
        "            src_img_path = os.path.join(category_path, img)\n",
        "\n",
        "            if i < train_split:\n",
        "                dest_folder = os.path.join(train_folder, category)\n",
        "            elif i < val_split:\n",
        "                dest_folder = os.path.join(val_folder, category)\n",
        "            else:\n",
        "                dest_folder = os.path.join(test_folder, category)\n",
        "\n",
        "            os.makedirs(dest_folder, exist_ok=True)\n",
        "            shutil.move(src_img_path, dest_folder)\n",
        "\n",
        "print(\"Dataset organized into Train, Validation, and Test sets!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u6BvcgivKKI",
        "outputId": "6c7017e1-dd50-47f5-9252-726dc45cc453"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset organized into Train, Validation, and Test sets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Dataset Preparation\n",
        "\n",
        "Dataset Description: The dataset contains 4,326 images of 5 flower categories."
      ],
      "metadata": {
        "id": "Kzu5Jg3Trm8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# Define paths\n",
        "train_dir = '/content/dataset/train'\n",
        "val_dir = '/content/dataset/val'\n",
        "test_dir = '/content/dataset/test'\n",
        "\n",
        "# Data Augmentation & Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Load datasets\n",
        "batch_size = 32\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22k1lNUYrqDf",
        "outputId": "5689b255-449a-496d-a41a-191d3722c7e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3452 images belonging to 5 classes.\n",
            "Found 430 images belonging to 5 classes.\n",
            "Found 435 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Model Implementation and Fine-Tuning"
      ],
      "metadata": {
        "id": "ktNm-ZJ6rzh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "# Load pre-trained VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base layers\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(5, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile and train top layers\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_generator, epochs=10, validation_data=val_generator)\n",
        "\n",
        "# Visualize feature maps (first convolutional layer)\n",
        "layer_output = base_model.get_layer('block1_conv1').output\n",
        "activation_model = Model(inputs=base_model.input, outputs=layer_output)\n",
        "example_image = next(train_generator)[0][0]\n",
        "activations = activation_model.predict(np.expand_dims(example_image, axis=0))\n",
        "\n",
        "# Fine-tune last 4 convolutional blocks\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_fine = model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TwRWHSnr3ER",
        "outputId": "19f08aca-660e-48c4-fcd7-d1a00fc2c226"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 666ms/step - accuracy: 0.6129 - loss: 28.3037 - val_accuracy: 0.8488 - val_loss: 2.0329\n",
            "Epoch 2/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 513ms/step - accuracy: 0.7612 - loss: 2.5172 - val_accuracy: 0.8442 - val_loss: 0.7250\n",
            "Epoch 3/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 526ms/step - accuracy: 0.7504 - loss: 0.9803 - val_accuracy: 0.8349 - val_loss: 0.8229\n",
            "Epoch 4/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 517ms/step - accuracy: 0.7948 - loss: 0.7341 - val_accuracy: 0.8488 - val_loss: 0.6013\n",
            "Epoch 5/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 514ms/step - accuracy: 0.7994 - loss: 0.7617 - val_accuracy: 0.8442 - val_loss: 0.6788\n",
            "Epoch 6/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 503ms/step - accuracy: 0.7950 - loss: 0.6634 - val_accuracy: 0.8628 - val_loss: 0.5941\n",
            "Epoch 7/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 502ms/step - accuracy: 0.8195 - loss: 0.5871 - val_accuracy: 0.8605 - val_loss: 0.7068\n",
            "Epoch 8/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 506ms/step - accuracy: 0.8234 - loss: 0.5623 - val_accuracy: 0.8558 - val_loss: 0.6334\n",
            "Epoch 9/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 522ms/step - accuracy: 0.8251 - loss: 0.5936 - val_accuracy: 0.8279 - val_loss: 0.7141\n",
            "Epoch 10/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 503ms/step - accuracy: 0.8115 - loss: 0.7221 - val_accuracy: 0.8558 - val_loss: 0.6653\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 543ms/step - accuracy: 0.8319 - loss: 0.5974 - val_accuracy: 0.8698 - val_loss: 0.6347\n",
            "Epoch 2/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 522ms/step - accuracy: 0.8803 - loss: 0.3998 - val_accuracy: 0.8860 - val_loss: 0.5267\n",
            "Epoch 3/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 526ms/step - accuracy: 0.8904 - loss: 0.2936 - val_accuracy: 0.8860 - val_loss: 0.4636\n",
            "Epoch 4/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 501ms/step - accuracy: 0.9108 - loss: 0.2780 - val_accuracy: 0.9186 - val_loss: 0.4105\n",
            "Epoch 5/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 496ms/step - accuracy: 0.9092 - loss: 0.2826 - val_accuracy: 0.9093 - val_loss: 0.5008\n",
            "Epoch 6/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 510ms/step - accuracy: 0.9347 - loss: 0.1895 - val_accuracy: 0.8930 - val_loss: 0.5253\n",
            "Epoch 7/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 496ms/step - accuracy: 0.9360 - loss: 0.1886 - val_accuracy: 0.9000 - val_loss: 0.4156\n",
            "Epoch 8/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 496ms/step - accuracy: 0.9359 - loss: 0.1927 - val_accuracy: 0.8930 - val_loss: 0.6511\n",
            "Epoch 9/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 499ms/step - accuracy: 0.9450 - loss: 0.1700 - val_accuracy: 0.9047 - val_loss: 0.7028\n",
            "Epoch 10/10\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 503ms/step - accuracy: 0.9360 - loss: 0.1810 - val_accuracy: 0.9140 - val_loss: 0.4119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Model Evaluation"
      ],
      "metadata": {
        "id": "g3bluTXLr494"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Evaluate test set\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_acc * 100:.2f}%')\n",
        "\n",
        "# Generate predictions\n",
        "y_true = test_generator.classes\n",
        "y_pred = np.argmax(model.predict(test_generator), axis=1)\n",
        "\n",
        "# Performance metrics\n",
        "print(classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys())))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz4DBhxCr7or",
        "outputId": "7ec28dee-ef41-47e1-d431-6348ffebc762"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.9256 - loss: 0.2722\n",
            "Test Accuracy: 91.49%\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 257ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       daisy       0.95      0.94      0.94        77\n",
            "   dandelion       0.89      0.95      0.92       106\n",
            "        rose       0.90      0.90      0.90        79\n",
            "   sunflower       0.93      0.91      0.92        74\n",
            "       tulip       0.92      0.88      0.90        99\n",
            "\n",
            "    accuracy                           0.91       435\n",
            "   macro avg       0.92      0.91      0.92       435\n",
            "weighted avg       0.92      0.91      0.91       435\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 72   3   1   0   1]\n",
            " [  3 101   1   0   1]\n",
            " [  1   1  71   2   4]\n",
            " [  0   5   0  67   2]\n",
            " [  0   3   6   3  87]]\n"
          ]
        }
      ]
    }
  ]
}
